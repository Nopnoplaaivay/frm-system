{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>DXG</th>\n",
       "      <th>TCH</th>\n",
       "      <th>HDG</th>\n",
       "      <th>HDC</th>\n",
       "      <th>KDH</th>\n",
       "      <th>IDC</th>\n",
       "      <th>KBC</th>\n",
       "      <th>DPG</th>\n",
       "      <th>VHM</th>\n",
       "      <th>NLG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/27/2024</td>\n",
       "      <td>15,700</td>\n",
       "      <td>15,450</td>\n",
       "      <td>29,050</td>\n",
       "      <td>25,150</td>\n",
       "      <td>35,800</td>\n",
       "      <td>55,900</td>\n",
       "      <td>27,650</td>\n",
       "      <td>46,350</td>\n",
       "      <td>40,350</td>\n",
       "      <td>36,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/26/2024</td>\n",
       "      <td>16,000</td>\n",
       "      <td>15,650</td>\n",
       "      <td>29,800</td>\n",
       "      <td>25,350</td>\n",
       "      <td>35,850</td>\n",
       "      <td>56,200</td>\n",
       "      <td>27,550</td>\n",
       "      <td>47,750</td>\n",
       "      <td>40,650</td>\n",
       "      <td>36,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/25/2024</td>\n",
       "      <td>16,300</td>\n",
       "      <td>15,600</td>\n",
       "      <td>29,900</td>\n",
       "      <td>25,350</td>\n",
       "      <td>35,900</td>\n",
       "      <td>56,300</td>\n",
       "      <td>28,150</td>\n",
       "      <td>48,050</td>\n",
       "      <td>40,600</td>\n",
       "      <td>36,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/24/2024</td>\n",
       "      <td>16,450</td>\n",
       "      <td>15,100</td>\n",
       "      <td>30,000</td>\n",
       "      <td>25,300</td>\n",
       "      <td>35,950</td>\n",
       "      <td>56,000</td>\n",
       "      <td>27,600</td>\n",
       "      <td>47,700</td>\n",
       "      <td>40,350</td>\n",
       "      <td>35,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/23/2024</td>\n",
       "      <td>17,650</td>\n",
       "      <td>15,300</td>\n",
       "      <td>30,800</td>\n",
       "      <td>26,100</td>\n",
       "      <td>35,900</td>\n",
       "      <td>56,200</td>\n",
       "      <td>27,800</td>\n",
       "      <td>50,200</td>\n",
       "      <td>40,600</td>\n",
       "      <td>36,250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>01/03/2020</td>\n",
       "      <td>13,900</td>\n",
       "      <td>33,700</td>\n",
       "      <td>30,650</td>\n",
       "      <td>24,500</td>\n",
       "      <td>26,400</td>\n",
       "      <td>18,300</td>\n",
       "      <td>15,300</td>\n",
       "      <td>39,600</td>\n",
       "      <td>85,200</td>\n",
       "      <td>27,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>01/02/2020</td>\n",
       "      <td>14,300</td>\n",
       "      <td>33,300</td>\n",
       "      <td>30,000</td>\n",
       "      <td>24,500</td>\n",
       "      <td>26,500</td>\n",
       "      <td>18,400</td>\n",
       "      <td>15,200</td>\n",
       "      <td>40,700</td>\n",
       "      <td>84,900</td>\n",
       "      <td>27,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>12/31/2019</td>\n",
       "      <td>14,500</td>\n",
       "      <td>32,650</td>\n",
       "      <td>30,000</td>\n",
       "      <td>23,800</td>\n",
       "      <td>26,900</td>\n",
       "      <td>18,900</td>\n",
       "      <td>15,450</td>\n",
       "      <td>41,000</td>\n",
       "      <td>84,800</td>\n",
       "      <td>27,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>12/30/2019</td>\n",
       "      <td>14,650</td>\n",
       "      <td>32,100</td>\n",
       "      <td>30,150</td>\n",
       "      <td>23,900</td>\n",
       "      <td>27,000</td>\n",
       "      <td>18,900</td>\n",
       "      <td>15,450</td>\n",
       "      <td>41,300</td>\n",
       "      <td>85,500</td>\n",
       "      <td>27,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>12/27/2019</td>\n",
       "      <td>14,600</td>\n",
       "      <td>31,700</td>\n",
       "      <td>30,700</td>\n",
       "      <td>24,500</td>\n",
       "      <td>26,900</td>\n",
       "      <td>18,800</td>\n",
       "      <td>15,400</td>\n",
       "      <td>42,000</td>\n",
       "      <td>84,500</td>\n",
       "      <td>27,350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1251 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date     DXG     TCH     HDG     HDC     KDH     IDC     KBC  \\\n",
       "0     12/27/2024  15,700  15,450  29,050  25,150  35,800  55,900  27,650   \n",
       "1     12/26/2024  16,000  15,650  29,800  25,350  35,850  56,200  27,550   \n",
       "2     12/25/2024  16,300  15,600  29,900  25,350  35,900  56,300  28,150   \n",
       "3     12/24/2024  16,450  15,100  30,000  25,300  35,950  56,000  27,600   \n",
       "4     12/23/2024  17,650  15,300  30,800  26,100  35,900  56,200  27,800   \n",
       "...          ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "1246  01/03/2020  13,900  33,700  30,650  24,500  26,400  18,300  15,300   \n",
       "1247  01/02/2020  14,300  33,300  30,000  24,500  26,500  18,400  15,200   \n",
       "1248  12/31/2019  14,500  32,650  30,000  23,800  26,900  18,900  15,450   \n",
       "1249  12/30/2019  14,650  32,100  30,150  23,900  27,000  18,900  15,450   \n",
       "1250  12/27/2019  14,600  31,700  30,700  24,500  26,900  18,800  15,400   \n",
       "\n",
       "         DPG     VHM     NLG  \n",
       "0     46,350  40,350  36,400  \n",
       "1     47,750  40,650  36,200  \n",
       "2     48,050  40,600  36,300  \n",
       "3     47,700  40,350  35,700  \n",
       "4     50,200  40,600  36,250  \n",
       "...      ...     ...     ...  \n",
       "1246  39,600  85,200  27,000  \n",
       "1247  40,700  84,900  27,500  \n",
       "1248  41,000  84,800  27,500  \n",
       "1249  41,300  85,500  27,500  \n",
       "1250  42,000  84,500  27,350  \n",
       "\n",
       "[1251 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../src/data/fiinx/raw_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# config.py\n",
    "from typing import List, Dict\n",
    "\n",
    "INDICES: List[str] = [\n",
    "    'IonQ', 'Rigetti Computing', 'Quantum Computing Inc.',\n",
    "    'D-Wave Quantum', 'Alphabet', 'IBM',\n",
    "    'Microsoft', 'Nvidia', 'Defiance Quantum ETF', 'Global X Future Analytics Tech'\n",
    "]\n",
    "\n",
    "SYMBOLS: List[str] = [\n",
    "    'IONQ', 'RGTI', 'QUBT', 'QBTS', 'GOOGL', \n",
    "    'IBM', 'MSFT', 'NVDA', 'QTUM', 'AIQ'\n",
    "]\n",
    "\n",
    "# Model configuration\n",
    "SEQUENCE_LENGTH: int = 63\n",
    "HIDDEN_SIZE: int = 32\n",
    "NUM_LAYERS: int = 4\n",
    "BATCH_SIZE: int = 32\n",
    "LEARNING_RATE: float = 0.001\n",
    "EPOCHS: int = 100\n",
    "FORECAST_DAYS: int = 63  # 3 months\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# data_loader.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "class StockDataProcessor:\n",
    "    def __init__(self, csv_path: str):\n",
    "        self.df = self._load_data(csv_path)\n",
    "        self.scalers = {}\n",
    "        \n",
    "    def _load_data(self, csv_path: str) -> pd.DataFrame:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df = df.dropna(axis=0)\n",
    "        df.columns = ['Date'] + SYMBOLS\n",
    "        return df.reset_index(drop=True)\n",
    "    \n",
    "    def prepare_data(self, symbol: str) -> Dict:\n",
    "        data = self.df[symbol].values.reshape(-1, 1)\n",
    "        self.scalers[symbol] = MinMaxScaler()\n",
    "        data_normalized = self.scalers[symbol].fit_transform(data)\n",
    "        \n",
    "        return self._create_sequences(data_normalized, symbol)\n",
    "    \n",
    "    def _create_sequences(self, data: np.ndarray, symbol: str) -> Dict:\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - SEQUENCE_LENGTH):\n",
    "            X.append(data[i:i+SEQUENCE_LENGTH])\n",
    "            y.append(data[i+SEQUENCE_LENGTH])\n",
    "            \n",
    "        X, y = np.array(X), np.array(y)\n",
    "        return self._split_and_convert(X, y, symbol)\n",
    "    \n",
    "    def _split_and_convert(self, X: np.ndarray, y: np.ndarray, symbol: str) -> Dict:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "        X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "        y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "        \n",
    "        return {\n",
    "            'train_loader': DataLoader(\n",
    "                list(zip(X_train, y_train)), \n",
    "                batch_size=BATCH_SIZE, \n",
    "                shuffle=True\n",
    "            ),\n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test,\n",
    "            'scaler': self.scalers[symbol]\n",
    "        }\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# model.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class StockRNN(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, num_layers: int, output_size: int):\n",
    "        super(StockRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.rnn(x, (h0, c0))\n",
    "        return self.fc(out[:, -1, :])\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# trainer.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Dict\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, model: nn.Module, criterion: nn.Module, optimizer: torch.optim.Optimizer):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "    \n",
    "    def train_model(self, train_loader: torch.utils.data.DataLoader) -> None:\n",
    "        for epoch in range(EPOCHS):\n",
    "            self.model.train()\n",
    "            epoch_loss = 0\n",
    "            for batch_X, batch_y in train_loader:\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(batch_X)\n",
    "                loss = self.criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "            \n",
    "            print(f'Epoch {epoch+1}/{EPOCHS}, Loss: {epoch_loss/len(train_loader):.4f}')\n",
    "    \n",
    "    def predict(self, X_test: torch.Tensor) -> np.ndarray:\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            return self.model(X_test).numpy()\n",
    "    \n",
    "    def predict_future(self, last_sequence: np.ndarray) -> np.ndarray:\n",
    "        self.model.eval()\n",
    "        future_predictions = []\n",
    "        temp_sequence = np.copy(last_sequence)\n",
    "        \n",
    "        for _ in range(FORECAST_DAYS):\n",
    "            with torch.no_grad():\n",
    "                future_pred = self.model(\n",
    "                    torch.tensor(temp_sequence, dtype=torch.float32)\n",
    "                ).numpy()\n",
    "                future_predictions.append(future_pred[0, 0])\n",
    "                temp_sequence = np.append(\n",
    "                    temp_sequence[:, 1:, :],\n",
    "                    future_pred.reshape(1, 1, 1),\n",
    "                    axis=1\n",
    "                )\n",
    "        \n",
    "        return np.array(future_predictions).reshape(-1, 1)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# visualization.py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class StockVisualizer:\n",
    "    @staticmethod\n",
    "    def plot_predictions(\n",
    "        actual: np.ndarray,\n",
    "        predicted: np.ndarray,\n",
    "        future_predicted: np.ndarray,\n",
    "        symbol: str\n",
    "    ) -> None:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "        \n",
    "        # Test set predictions\n",
    "        axes[0].plot(actual, label='Actual Prices', color='blue')\n",
    "        axes[0].plot(predicted, label='Predicted Prices', marker='o', alpha=0.5, color='red')\n",
    "        axes[0].legend()\n",
    "        axes[0].set_title(f'{symbol} Price Prediction (Test Set)', weight='bold')\n",
    "        axes[0].set_xlabel('Time [days]', fontsize=12, weight='bold')\n",
    "        axes[0].set_ylabel('Value [USD]', fontsize=12, weight='bold')\n",
    "        axes[0].grid(True)\n",
    "        \n",
    "        # Future predictions\n",
    "        axes[1].plot(future_predicted, label='Predicted Future Prices', color='red', alpha=0.8)\n",
    "        axes[1].legend()\n",
    "        axes[1].set_title(f'{symbol} 3-Month Price Forecast', weight='bold')\n",
    "        axes[1].set_xlabel('Time [days]', fontsize=12, weight='bold')\n",
    "        axes[1].set_ylabel('Value [USD]', fontsize=12, weight='bold')\n",
    "        axes[1].grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{symbol}.jpg', dpi=600)\n",
    "        plt.close()\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# main.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from config import *\n",
    "from data_loader import StockDataProcessor\n",
    "from model import StockRNN\n",
    "from trainer import ModelTrainer\n",
    "from visualization import StockVisualizer\n",
    "\n",
    "def process_symbol(symbol: str, data_processor: StockDataProcessor) -> None:\n",
    "    # Prepare data\n",
    "    data_dict = data_processor.prepare_data(symbol)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = StockRNN(\n",
    "        input_size=1,\n",
    "        hidden_size=HIDDEN_SIZE,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        output_size=1\n",
    "    )\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = ModelTrainer(\n",
    "        model=model,\n",
    "        criterion=nn.MSELoss(),\n",
    "        optimizer=torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    print(f\"\\nTraining model for {symbol}\")\n",
    "    trainer.train_model(data_dict['train_loader'])\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = trainer.predict(data_dict['X_test'])\n",
    "    y_test_np = data_dict['y_test'].numpy()\n",
    "    \n",
    "    # Inverse transform predictions\n",
    "    predictions = data_dict['scaler'].inverse_transform(predictions)\n",
    "    y_test_np = data_dict['scaler'].inverse_transform(y_test_np)\n",
    "    \n",
    "    # Future predictions\n",
    "    last_sequence = data_dict['X_test'][-2].reshape(1, SEQUENCE_LENGTH, 1)\n",
    "    future_predictions = trainer.predict_future(last_sequence)\n",
    "    future_predictions = data_dict['scaler'].inverse_transform(future_predictions)\n",
    "    \n",
    "    # Visualize results\n",
    "    StockVisualizer.plot_predictions(\n",
    "        actual=y_test_np,\n",
    "        predicted=predictions,\n",
    "        future_predicted=future_predictions,\n",
    "        symbol=symbol\n",
    "    )\n",
    "\n",
    "def main():\n",
    "    data_processor = StockDataProcessor('quantum_technology_indices_prices.csv')\n",
    "    \n",
    "    for symbol in SYMBOLS:\n",
    "        process_symbol(symbol, data_processor)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
